{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "rFvWqJ12CUfd",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "iX4FKLJJCUfy",
        "YikIvZK0CUfw",
        "VASmZrgcCUfu",
        "Hm0DonluCUf7",
        "xZQ8iQ-rCUf8",
        "HXwmapQVCUf8",
        "dONrzMiPCUf9",
        "E2OG4YjfCUf2",
        "usi7_TG6CUgB",
        "LMvtM6w0CUf5",
        "OtVIzO54CUf_",
        "HJIqs3m_CUgG",
        "Dz-svydzCUgH",
        "J7mVOjjZCUgD",
        "JFDdlc_bCUgK",
        "DsVsQeFDCUgK",
        "WrD7Hg5PCUgF",
        "FDzcmxA2CUgI",
        "bN4XqXLbCUgJ",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "fF3858GYyt-u",
        "3yB-zSqbpUZe",
        "Nff-vKELpZyI",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "rDQLFoF4Ahg3",
        "XGtXMbkuBWEX",
        "kfWm8BVABiQa",
        "-Kee-DAl2viO"
      ],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Bike sharing demand Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name -**            M Dhanunjaya\n",
        "\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**\n",
        "\n",
        "Rental bikes have become increasingly popular in urban cities, offering enhanced mobility comfort. The key to ensuring a smooth experience for the public is making rental bikes readily available and accessible at all times, reducing waiting times. However, one major challenge lies in maintaining a stable supply of rental bikes throughout the city. To address this concern, accurate predictions of the required bike count at each hour are crucial.\n",
        "\n",
        "In this data analysis project, we started by importing the necessary libraries and examining our dataset, which contains 8760 rows and 14 columns, with no duplicate or missing data.\n",
        "\n",
        "After initial exploration, we focused on studying the individual features and the data they represent. We noticed that the 'Date' column was in 'object' datatype, so we converted it to the datetime datatype. From this column, we extracted additional features such as 'Date', 'month', 'year', and the number of weeks. Subsequently, we dropped the original 'Date' column and renamed certain columns for convenience.\n",
        "\n",
        "Next, we proceeded with data visualization, creating various charts and graphs to gain useful insights. Based on the visualizations, we formulated three hypothetical statements and performed hypothesis tests to validate them. The statements were:\n",
        "\n",
        "The average bike count in Seoul city at any point in time is greater than 100.\n",
        "The average temperature in Seoul city at any point is greater than 10 degrees Celsius.\n",
        "The standard deviation of humidity in Seoul city is 20.\n",
        "Following the exploratory data analysis, we addressed some data preprocessing steps. We performed one-hot encoding on categorical features while dropping the first column to avoid multicollinearity. To deal with the right-skewed distribution of the dependent variable 'Rented_bike_count,' we applied a square root transformation to achieve a more normal distribution. Additionally, we used MinMax scaling to scale our features. Finally, we split the data into an 80-20 train-test ratio for model training and evaluation.\n",
        "\n",
        "Moving on to the machine learning phase, we implemented various models and calculated various statistical parameters to assess their performance. After comparing the models, we found that the Random Forest Regressor exhibited the best performance in predicting the demand for city bikes for a particular hour.\n",
        "\n",
        "In conclusion, deploying the Random Forest Regressor model can significantly help the bike rental company accurately predict the bike demand, enabling them to efficiently meet the city's bike rental needs."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n",
        "https://github.com/Dhana009/Bike-sharing-demand-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "\n",
        "The main objective of this project is to create a robust machine learning model capable of predicting the demand for rental bikes in urban cities on an hourly basis. The primary challenge addressed here is to ensure a consistent and adequate supply of rental bikes while minimizing waiting times for users. By accurately forecasting the demand for rental bikes at different hours of the day, the project aims to optimize bike-sharing systems in cities. The ultimate goal is to enhance the availability and accessibility of rental bikes, enabling cities to allocate resources effectively and meet the demands of their bike-sharing services efficiently."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import chi2\n",
        "from scipy.stats import t\n",
        "from scipy.stats import f\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#setting font size throughout the notebook\n",
        "plt.rcParams.update({'font.size': 14})"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# reading data file\n",
        "dir_path = '/content/drive/MyDrive/Almabetter/capstone projects/bike/SeoulBikeData.csv'\n",
        "df = pd.read_csv(dir_path, encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "pkCTo80qBJ87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "x = df.shape\n",
        "print(f'Dataset as {x[0]} rows & {x[1]} columns in total')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "dup = df.duplicated().sum()\n",
        "print(f'total no. of duplicates are {dup} in the dataset')"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n",
        "plt.rcParams['figure.figsize'] = (25, 5)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Columns Information:**\n",
        "\n",
        "There are no null values in the total dataset.\n",
        "\n",
        "**Date** has information about date in format year-month-day and it is in the object data type, we do need convert it to date type, if needed.\n",
        "\n",
        "**Rented Bike count** show the count of bikes rented and it is in the integer datatype\n",
        "\n",
        "**Hour** - shows the no of hours the bikes rented\n",
        "\n",
        "**Temperature** Temperature are in the Celsius format\n",
        "\n",
        "**Humidity** - humidity is given with respect to the particular hour on the given date (in %)\n",
        "\n",
        "**Windspeed** - Windspeed is given with respect to the particular hour on the given date (in m/s)\n",
        "\n",
        "**Visibility** - Visibility is given with respect to the particular hour on the given date (upto 10m)\n",
        "\n",
        "**Dew point temperature** - Dew point temperature is given with respect to the particular hour on the given date (in Celsius)\n",
        "\n",
        "**Solar radiation** - Solar Radition is given with respect to the particular hour on the given date (in MJ/m2)\n",
        "\n",
        "**Rainfall** - Rainfall is given with respect to the particular hour on the given date (in mm)\n",
        "\n",
        "**Snowfall** - Snowfall is given with respect to the particular hour on the given date (in cm)\n",
        "\n",
        "**Seasons** - shows the season it is rented like \"Winter, Spring, Summer, Autumn\"\n",
        "\n",
        "**Holiday** - show if that day is a holiday or not\n",
        "\n",
        "**Functional Day** - shows if the hours were functional or not in that day"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include = 'all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Columns Information:**\n",
        "\n",
        "There are no null values in the total dataset.\n",
        "\n",
        "**Date** has information about date in format year-month-day and it is in the object data type, we do need convert it to date type, if needed.\n",
        "\n",
        "**Rented Bike count** show the count of bikes rented and it is in the integer datatype\n",
        "\n",
        "**Hour** - shows the no of hours the bikes rented\n",
        "\n",
        "**Temperature** Temperature are in the Celsius format\n",
        "\n",
        "**Humidity** - humidity is given with respect to the particular hour on the given date (in %)\n",
        "\n",
        "**Windspeed** - Windspeed is given with respect to the particular hour on the given date (in m/s)\n",
        "\n",
        "**Visibility** - Visibility is given with respect to the particular hour on the given date (upto 10m)\n",
        "\n",
        "**Dew point temperature** - Dew point temperature is given with respect to the particular hour on the given date (in Celsius)\n",
        "\n",
        "**Solar radiation** - Solar Radition is given with respect to the particular hour on the given date (in MJ/m2)\n",
        "\n",
        "**Rainfall** - Rainfall is given with respect to the particular hour on the given date (in mm)\n",
        "\n",
        "**Snowfall** - Snowfall is given with respect to the particular hour on the given date (in cm)\n",
        "\n",
        "**Seasons** - shows the season it is rented like \"Winter, Spring, Summer, Autumn\"\n",
        "\n",
        "**Holiday** - show if that day is a holiday or not\n",
        "\n",
        "**Functional Day** - shows if the hours were functional or not in that day"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values\n",
        "for i in df.columns:\n",
        "  len_value = len(df[i].unique())\n",
        "  print(f\"The number of unique variables in {i} column are: {len_value}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "#converting Date column to date time format\n",
        "df['Date']=pd.to_datetime(df['Date'])\n",
        "\n",
        "# creating new colums\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day\n",
        "\n",
        "# using date column to get the week number\n",
        "df['Week Number'] = df['Date'].dt.week\n",
        "\n",
        "# lets drop the date column\n",
        "df.drop(columns=['Date'],axis='columns',inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming the column names for better understanding\n",
        "df.rename(columns={'Temperature(°C)':'Temperature',\n",
        "                       'Humidity(%)':'Humidity',\n",
        "                       'Wind speed (m/s)':'Wind Speed',\n",
        "                       'Visibility (10m)':'Visibility',\n",
        "                       'Dew point temperature(°C)':'Dew Point Temperature',\n",
        "                       'Solar Radiation (MJ/m2)':'Solar Radiation',\n",
        "                       'Rainfall(mm)':'Rainfall',\n",
        "                        'Snowfall (cm)':'Snowfall'\n",
        "                       }, inplace = True)"
      ],
      "metadata": {
        "id": "n4ky6r046tOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". There were no missing values in the dataset\n",
        "\n",
        ". We have extracted Day, Month, year and week number from date colum and then we dropped the date column from the dataset\n",
        "\n",
        ". Finally we renamed the column for better understanding"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFvWqJ12CUfd"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 1\n",
        "total rented bike w.r.t Holiday, functioning Day, season and Year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "# we are using the columns Holiday, Functioning day, Seasons, and Year to plot a graph to check the total rented bikes sum with respect to each category\n",
        "\n",
        "# creating a list to loop\n",
        "x = ['Year','Seasons','Holiday', 'Functioning Day']\n",
        "\n",
        "# looping for every element in the list\n",
        "for elements in x:\n",
        "  bike_sum = df.groupby(elements)['Rented Bike Count'].sum().sort_values(ascending = False)\n",
        "  plt.rcParams['figure.figsize'] = (5,5)\n",
        "  # plotting bar plot\n",
        "  bike_sum.plot.bar()\n",
        "\n",
        "  #setting colum chart title to infer about the chart\n",
        "  plt.title(f'Total Sum of Rented Bikes with {elements} column')\n",
        "  plt.show()\n",
        "  # printing values obtained for reference\n",
        "  print(bike_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "with bar charts we can visuallize the sum better and helps us interpret them in a better way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "\n",
        "On regular days (non-holiday), the total number of bikes rented is 5,956,419, while on holidays, it is 215,895.\n",
        "\n",
        "On functioning days, the total bikes rented amount to 6,172,314, whereas on non-functioning days, there were no bike rentals, resulting in a count of 0.\n",
        "\n",
        "The bike rentals for different seasons are as follows:\n",
        "\n",
        "Summer: 2,283,234 rentals\n",
        "Autumn: 1,790,002 rentals\n",
        "Spring: 1,611,909 rentals\n",
        "Winter: 487,169 rentals.\n",
        "\n",
        "It is evident that bike rentals are significantly lower during winter compared to other seasons, with summer experiencing the highest rental activity.\n",
        "In the year 2018, the total number of bikes rented was 5,986,984, while in 2017, it was 185,330."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        ". On operational days, no bikes were rented, indicating that on non-operational days, there were also no bike rentals. This lack of business on non-operational days has resulted in the cessation of operations.\n",
        "\n",
        ". Winter months witness a decline in the number of bike rentals, negatively impacting the business. Conversely, during summer, the business experiences a positive impact, with a higher number of bike rentals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 2\n",
        "Spread of various values in Holiday, Functioning Day, Seasons and Year\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "#The following code creates pie charts to visualize the distribution of unique values in the DataFrame for the columns 'Holiday', 'Functioning Day', 'Seasons', and 'Year'.\n",
        "#Since these columns have a small number of unique values, pie charts are chosen for this analysis.\n",
        "\n",
        "# List of columns to analyze\n",
        "columns_to_analyze = ['Holiday', 'Functioning Day', 'Seasons', 'Year']\n",
        "\n",
        "# Loop through each element in the list\n",
        "for column in columns_to_analyze:\n",
        "    # Obtain value counts for each unique value in the column\n",
        "    value_counts = df[column].value_counts()\n",
        "    plt.rcParams['figure.figsize'] = (5, 5)\n",
        "\n",
        "    # Create a pie chart to visualize the distribution of unique values\n",
        "    # Pctdistance 0.6 is set to display the value inside the chart; if set more than 1, it'll display outside the chart.\n",
        "    value_counts.plot(kind='pie', autopct='%1.1f%%', pctdistance=0.6)\n",
        "\n",
        "    # Set the title for the pie chart\n",
        "    plt.title(f'Distribution of Unique Values for {column}')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "\n",
        "\n",
        "Pie charts are favored for their ease of interpretation, allowing a clear understanding of the relative proportions of different categories presented as percentages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "The data reveals that 95% of the recorded days are categorized as working days (not holidays), while holidays constitute 4.9% of the total days.\n",
        "\n",
        "A significant majority, approximately 96.6%, of the data corresponds to functioning days, whereas the remaining data corresponds to non-functioning days.\n",
        "\n",
        "The data for different seasons shows a nearly equal distribution, with each season accounting for approximately 25% of the total data.\n",
        "\n",
        "The dataset comprises records from the years 2017 and 2018. The majority of the data, approximately 91.5%, belongs to the year 2018, while the year 2017 accounts for the remaining 8.5%.\n",
        "\n",
        "Before dropping the date column, it was determined that the dataset spans from the start date of January 12, 2017, to the last date of December 11, 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MZBGiOxPSMBE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "The analysis indicates that the majority of days are classified as functional days and not holidays.\n",
        "\n",
        "The dataset includes data for all seasons, which strengthens the analysis by capturing information for both functioning days and holidays across various seasons.\n",
        "\n",
        "The recorded data covers a time range starting from January 12, 2017, and ending on December 11, 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX4FKLJJCUfy"
      },
      "source": [
        "#### Chart - 3\n",
        "Total Bike rented with respect to vairous rainfall values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEmEyom9CUfy"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "#The following code generates two bar plots to visualize the total number of bikes rented with respect to various rainfall values.\n",
        "#The first plot shows the raw data, while the second plot applies a log transformation to enhance visibility.\n",
        "\n",
        "# Grouping data by 'Rainfall' and calculating the sum of 'Rented Bike Count'\n",
        "rainfall_rent = df.groupby(['Rainfall'])['Rented Bike Count'].sum()\n",
        "\n",
        "# Setting plot size\n",
        "plt.rcParams['figure.figsize'] = (20, 5)\n",
        "\n",
        "# Creating a bar plot for raw data\n",
        "rainfall_rent.plot.bar()\n",
        "plt.title('Total Bikes Rented with Respect to Various Rainfall Values')\n",
        "plt.show()\n",
        "\n",
        "# Applying log transformation to the data for better visualization\n",
        "rainfall_rent_log = np.log(rainfall_rent)\n",
        "\n",
        "# Creating a bar plot for log-transformed data\n",
        "rainfall_rent_log.plot.bar()\n",
        "plt.title('Total Bikes Rented with Respect to Various Rainfall Values (Log Transformed)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To4BVC7ECUfz"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHfZNpjzCUfz"
      },
      "source": [
        "Bar charts give a better understanding for the understanding this situation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YjO9dZqCUfz"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LliVx9BYCUf0"
      },
      "source": [
        "After examining the data, it became apparent that bike rentals were notably higher on days when there was no rainfall (rainfall = 0.0). Nevertheless, upon further analysis, when we omitted the data points with zero rainfall, we discovered that the majority of bike rentals took place during periods with lower rainfall values. This observation suggests that people tend to rent bikes more often during light rain conditions rather than during heavy rainfall or completely dry weather."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZkmny3ECUf1"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b_HolQuCUf2"
      },
      "source": [
        "From the data, it is evident that people tend to rent bikes more during periods with lower rainfall. Conversely, as the rainfall increases, bike rentals experience a decline in sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YikIvZK0CUfw"
      },
      "source": [
        "#### Chart - 4\n",
        "Hourly Bike rental with respect to Seasons, Holiday, and year\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue-oow-wCUfw"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "# The following code generates point plots to explore the bike rentals with respect to different parameters: Seasons, Holiday, Functioning Day, and Year.\n",
        "\n",
        "# List of parameters to explore\n",
        "Parameters = ['Seasons', 'Holiday', 'Functioning Day', 'Year']\n",
        "\n",
        "# Looping through each parameter\n",
        "for param in Parameters:\n",
        "    # Setting the title for the point plot\n",
        "    plt.title(f'Hourly Bike Rentals with Respect to {param}')\n",
        "\n",
        "    # Creating the point plot using seaborn\n",
        "    sns.pointplot(data=df, x=\"Hour\", y=\"Rented Bike Count\", hue=param)\n",
        "\n",
        "    # Displaying the plot\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHFBGEKVCUfw"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z6PR50gCUfw"
      },
      "source": [
        "Sinc the data ranges from 0 to 23 as number of hours, a line chart can represent the data very well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngs1IyOgCUfx"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_5ns6KbCUfx"
      },
      "source": [
        "The analysis reveals that the peak hours for bike rentals are at 8 AM and 6 PM, suggesting a strong correlation with typical office commuting hours. This pattern implies that people are likely renting bikes to travel to and from their workplaces.\n",
        "\n",
        "It was observed that bike rentals on non-functioning days are non-existent, indicating zero demand for bikes during days when the business is not operational.\n",
        "\n",
        "Bike demand shows a notable increase during the summer season, whereas it declines during the winter months. This seasonal trend highlights that more people opt for bike rentals in the warmer months, while the demand decreases during the colder winter season."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-x_zqHTCUfx"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsjaVwIOCUfy"
      },
      "source": [
        "It's evident from the data that bikes are rented most frequently at 8 AM (8:00 AM) and 6 PM (6:00 PM). This trend suggests that bike rentals are heavily influenced by the time of day. The pattern strongly indicates that people are likely using bikes to commute to work in the morning and return home in the evening. Biking seems to be a popular choice for daily office travel during these peak hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VASmZrgcCUfu"
      },
      "source": [
        "#### Chart - 5\n",
        "Total rented bikes with respect to year and month (Bar Plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4kTmMbuCUfu"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "# To further understand the variations in bike rentals with respect to different months of the business year,\n",
        "# a bar chart is plotted based on the observations made in Chart 1 regarding the bike rentals during various seasons.\n",
        "\n",
        "# Grouping data by 'Year' and 'Month', and calculating the sum of 'Rented Bike Count'\n",
        "group_by_year_month = df.groupby(['Year', 'Month'])['Rented Bike Count'].sum()\n",
        "\n",
        "# Setting plot size\n",
        "plt.rcParams['figure.figsize'] = (20, 5)\n",
        "\n",
        "# Creating a bar chart to visualize bike rentals with respect to various months of the business year\n",
        "group_by_year_month.plot.bar()\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGyxP8RuCUfu"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlF6dCrLCUfu"
      },
      "source": [
        "A verticle bar represents the total in a better way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhOaM7zYCUfu"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHnu1zc8CUfv"
      },
      "source": [
        "\n",
        "\n",
        "From the bar chart, it becomes evident that the company experienced relatively lower bike rentals during the first 11 months of the business year. However, starting from December 2017, there was a noticeable spike in bike rentals. Although the spike in December was not exceptionally high, the growth in bike rentals appears to be significant. This observation suggests that there was a positive trend in bike rentals towards the end of the year, indicating potential growth and increased demand for bike rentals during that period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFSXGyvxCUfv"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpXKLBImCUfv"
      },
      "source": [
        "After maintaining a stable position in the market for 11 months, the company's sales started to show growth. This indicates that the company experienced a period of stability and then began to witness an upward trend in sales, signifying a positive development in its business performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm0DonluCUf7"
      },
      "source": [
        "#### Chart - 6\n",
        "weekly growth report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS_6w19TCUf7"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "# Grouping data by 'Year' and 'Week Number', and calculating the sum of 'Rented Bike Count' for each week\n",
        "Weekly_growth_in_rented_bike = df.groupby(['Year', 'Week Number'])['Rented Bike Count'].sum()\n",
        "\n",
        "# Setting the plot size\n",
        "plt.rcParams['figure.figsize'] = (20, 5)\n",
        "\n",
        "# Creating a bar chart to visualize the weekly growth in rented bikes\n",
        "Weekly_growth_in_rented_bike.plot.bar()\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZQ8iQ-rCUf8"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtGeDLoACUf8"
      },
      "source": [
        "A bar plot is well suited to explore this data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXwmapQVCUf8"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3W7UYygCUf8"
      },
      "source": [
        "\n",
        "Early weeks: slow growth\n",
        "\n",
        "Week 50 onwards: sales increase significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dONrzMiPCUf9"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwMBazi9CUf_"
      },
      "source": [
        "The data analysis indicates a positive growth trend in rented bikes, with the growth starting from the second week onwards. Moreover, a noteworthy observation is that during the 25th week of the second year, the maximum number of bikes was rented, suggesting a peak in bike rental demand during that particular period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2OG4YjfCUf2"
      },
      "source": [
        "#### Chart - 7\n",
        "Total bike rented with respect to various conditions of Wind Speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdEGf0UiCUf2"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "# Calculate the average number of rented bikes based on wind speed conditions\n",
        "average_bikes_rented = df.groupby(['Wind Speed'])['Rented Bike Count'].mean()\n",
        "\n",
        "# Set the plot size\n",
        "plt.rcParams['figure.figsize'] = (20, 5)\n",
        "\n",
        "# Apply log transformation to the data for improved visualization\n",
        "average_bikes_rented = np.log(average_bikes_rented)\n",
        "\n",
        "# Create a bar chart to visualize the average bike rentals with respect to various wind speed conditions\n",
        "average_bikes_rented.plot.bar()\n",
        "\n",
        "# Set the chart title\n",
        "plt.title('Average Bike Rentals with Respect to Wind Speed Conditions')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "# Print separator lines\n",
        "print('-'*100)\n",
        "print('Wind speed has minimal impact on bike rentals; the average is relatively consistent across different wind speed conditions.')\n",
        "print('-'*100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_UttGZpCUf3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZTSM99eCUf3"
      },
      "source": [
        "Bar charts give a better understanding for the understanding this situation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj0PEKc5CUf4"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hok4DiCJCUf4"
      },
      "source": [
        "data is uniformly distributed, we see that the wind speed doesnot affect the bike renting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MJwwb3xCUf4"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSuWmqrfCUf4"
      },
      "source": [
        "Bike rentals are preferred by people when the wind speed is moderate, typically ranging from 0.3 to 3.4. This observation suggests that wind speed does have an impact on bike rental preferences, as riders seem to favor biking during these moderate wind conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usi7_TG6CUgB"
      },
      "source": [
        "#### Chart - 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9-e-YozCUgB"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "\n",
        "# Create a histogram to visualize the distribution of Solar Radiation\n",
        "plt.hist(df['Solar Radiation'], bins=50, color='blue', edgecolor='black')\n",
        "\n",
        "# Label the x and y axes\n",
        "plt.xlabel('Solar Radiation')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Set the chart title\n",
        "plt.title('Histogram for Solar Radiation')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJkzeF_CUgB"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHZfGQqyCUgC"
      },
      "source": [
        "Histogram chart shows the quantitave of rental bikes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viA4t19wCUgC"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1idd7HSCUgC"
      },
      "source": [
        "Demand of rental bikes is on the low soalar radiation i.e 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze5ZOSLjCUgC"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Smh4CnCUgD"
      },
      "source": [
        "\n",
        "People tend to avoid renting bikes when the solar radiation level exceeds 0.05."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMvtM6w0CUf5"
      },
      "source": [
        "#### Chart - 9\n",
        "Total bike rented with respect to various weather conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiQ1emvFCUf5"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "# Numerical features to visualize\n",
        "numerical_features = ['Humidity', 'Wind Speed', 'Visibility', 'Dew Point Temperature', 'Solar Radiation', 'Rainfall', 'Snowfall']\n",
        "\n",
        "# Loop through each numerical feature\n",
        "for feature in numerical_features:\n",
        "    # Group data by the feature and calculate the sum of 'Rented Bike Count'\n",
        "    temp_df = df.groupby([feature])['Rented Bike Count'].sum()\n",
        "    temp_df = temp_df.reset_index()\n",
        "\n",
        "    # Create a scatter plot and line plot to visualize 'Total Rented Bike Count' vs. the current feature\n",
        "    sns.scatterplot(data=temp_df, x=feature, y='Rented Bike Count')\n",
        "    sns.lineplot(x=feature, y='Rented Bike Count', data=temp_df)\n",
        "\n",
        "    # Labeling the x and y axes, and setting the title for the plot\n",
        "    plt.xlabel(feature, fontsize=12)\n",
        "    plt.ylabel('Total Rented Bike Count', fontsize=14)\n",
        "    plt.title(f'Total Rented Bike Count vs. {feature}', fontsize=14)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSkAblR6CUf5"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkNgIjh-CUf6"
      },
      "source": [
        "a line plot helps us understand the trends efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEx_9-L2CUf6"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI4DrPZ5CUf6"
      },
      "source": [
        "People prefer to rent bikes when the wind speed ranges from 0.3 to 4.\n",
        "\n",
        "Bike rentals increase when the visibility is high, specifically at 2000.\n",
        "\n",
        "Bike rentals are more likely when the dew point temperature falls within the range of -0.25 to 25.\n",
        "\n",
        "Lower solar radiation levels (0.0) correspond to an increase in bike rentals.\n",
        "\n",
        "Bike rentals are more common during periods of lower rainfall (0.2).\n",
        "\n",
        "Similarly, bike rentals are more likely when there is minimal snowfall (0.1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ9hifHoCUf7"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHzNs_I5CUf7"
      },
      "source": [
        "There is an impact of the weather conditions on the people renting bikes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtVIzO54CUf_"
      },
      "source": [
        "#### Chart - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aKuPCyPCUf_"
      },
      "outputs": [],
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "# Create a histogram to visualize the distribution of Visibility\n",
        "plt.hist(df['Visibility'], bins=50, color='blue', edgecolor='black')\n",
        "\n",
        "# Label the x and y axes\n",
        "plt.xlabel('Visibility')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Set the chart title\n",
        "plt.title('Histogram for Visibility')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTuSyCBjCUf_"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdVUF0_-CUgA"
      },
      "source": [
        "Histogram chart shows the quantitative of the visibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3_ichw4CUgA"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XkZDd6fCUgA"
      },
      "source": [
        "Histogram chart shows the rental bikes are on huge demand when the visibility is 2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbQv3_sfCUgA"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtnVVEErCUgB"
      },
      "source": [
        "When visibility is 2000 people prefer the most to rent bikes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJIqs3m_CUgG"
      },
      "source": [
        "#### Chart - 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpOPFyQxCUgH"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code\n",
        "\n",
        "# Applying square root to 'Rented Bike Count' to improve skewness\n",
        "plt.figure(figsize=(7, 3))\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Density')\n",
        "\n",
        "# Create a distribution plot with square root-transformed data\n",
        "ax = sns.distplot(np.sqrt(df['Rented Bike Count']), color=\"y\")\n",
        "\n",
        "# Add vertical lines for mean and median of the square root-transformed data\n",
        "ax.axvline(np.sqrt(df['Rented Bike Count']).mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(np.sqrt(df['Rented Bike Count']).median(), color='black', linestyle='dashed', linewidth=2)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz-svydzCUgH"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7HgcI9TCUgH"
      },
      "source": [
        "The ditribution chart shows the ditributon of the rent bike counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEtEarleCUgH"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxUynvJnCUgH"
      },
      "source": [
        "we found the mean and median distribution of the rented bikes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWxN35_2CUgI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_KlW4ZBCUgI"
      },
      "source": [
        "The mean and median of the rental bikes are approximately equal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7mVOjjZCUgD"
      },
      "source": [
        "#### Chart - 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OjQQnusCUgD"
      },
      "outputs": [],
      "source": [
        "# Chart - 12 visualization code\n",
        "\n",
        "\n",
        "# List of selected features\n",
        "selected_features = ['Temperature', 'Humidity', 'Wind Speed', 'Visibility', 'Dew Point Temperature', 'Solar Radiation', 'Rainfall', 'Snowfall']\n",
        "\n",
        "# Loop through each selected feature and create a histogram\n",
        "for col in selected_features:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(df[col], bins=50, color='blue', edgecolor='black')\n",
        "    plt.xlabel(col)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cXDrgKSCUgD"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v7u1yDCCUgD"
      },
      "source": [
        "histogram shows the better quantitative of the feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YVpnBJdCUgE"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYrqneyiCUgE"
      },
      "source": [
        "Weather conditions were explored, and the following observations were made:\n",
        "\n",
        "Temperature is normally distributed, with values ranging from -20 to 40.\n",
        "\n",
        "Humidity also follows a normal distribution, with values between 0 and 90.\n",
        "\n",
        "Wind speed exhibits a right-skewed distribution, varying from 0 to 7.\n",
        "\n",
        "Visibility has a left-skewed distribution, ranging from 0 to 2000.\n",
        "\n",
        "Dew point temperature is distributed symmetrically, with values spanning from -30 to 30.\n",
        "\n",
        "Solar radiation displays a highly right-skewed distribution, ranging from 0 to 3.5.\n",
        "\n",
        "Rainfall demonstrates a highly right-skewed distribution, varying from 0 to 35.\n",
        "\n",
        "Snowfall exhibits a highly right-skewed distribution, with values between 0 and 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkxZ1iPvCUgE"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IhXs-KLCUgE"
      },
      "source": [
        "We have analysed the various weather conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFDdlc_bCUgK"
      },
      "source": [
        "#### Chart - 13\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv1a4VWHCUgK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Columns selected for pair plot visualization\n",
        "selected_columns = ['Rented Bike Count', 'Temperature', 'Humidity', 'Wind Speed', 'Visibility', 'Solar Radiation', 'Rainfall', 'Snowfall', 'Holiday']\n",
        "pair_plot_df = df[selected_columns]\n",
        "\n",
        "# Create a pair plot using seaborn\n",
        "sns.pairplot(pair_plot_df, diag_kind=\"kde\", kind='reg', hue='Holiday')\n",
        "\n",
        "# Setting labels for better interpretation of the plot\n",
        "plt.title('Pair Plot')\n",
        "plt.ylabel('Feature/Property')\n",
        "plt.xlabel('Feature/Property')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsVsQeFDCUgK"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn9QVIgqCUgK"
      },
      "source": [
        "Pair plots are used to show relationship between various variables\n",
        "\n",
        "Pair plots can also help us explore the distribution of variables in your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r73HTCGyCUgL"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB8R7AAtCUgL"
      },
      "source": [
        "Observations from the pair plot:\n",
        "\n",
        "There is a positive correlation between wind speed and solar radiation.\n",
        "\n",
        "Temperature and rented bike count exhibit a strong positive correlation.\n",
        "\n",
        "Humidity and solar radiation are negatively correlated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrD7Hg5PCUgF"
      },
      "source": [
        "#### Chart - 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNU2_0WeCUgF"
      },
      "outputs": [],
      "source": [
        "# Chart - 14 visualization code\n",
        "\n",
        "# Printing regression plots for all the numerical features\n",
        "numerical_columns = list(df.select_dtypes(['int64', 'float64']).columns)\n",
        "numerical_features = pd.Index(numerical_columns)\n",
        "\n",
        "for col in numerical_features:\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sns.regplot(x=df[col], y=df['Rented Bike Count'], scatter_kws={\"color\": 'orange'}, line_kws={\"color\": \"black\"})\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Rented Bike Count')\n",
        "    plt.title(f'Regression Plot: {col} vs. Rented Bike Count')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbMEkWLHCUgF"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIRzs5yLCUgF"
      },
      "source": [
        "Linear Regression show the best fit line for the data i.e the avg increase in X with respect to Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmsN8f4ECUgG"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZEd8KfUCUgG"
      },
      "source": [
        "Insights from the regression plots:\n",
        "\n",
        "As the temperature (X) increases from -10 to 30, the demand for rental bikes (Y) also increases.\n",
        "\n",
        "An increase in humidity (X) is associated with a decrease in the demand for rental bikes (Y).\n",
        "\n",
        "For wind speed (X) ranging from 0 to 3, the demand for rental bikes (Y) increases.\n",
        "\n",
        "The visibility (X) does not show a clear relationship with the demand for rental bikes (Y), as indicated by the flat best-fit line.\n",
        "\n",
        "The dew point temperature (X) exhibits an increasing trend with respect to the demand for rental bikes (Y) based on the upward-sloping best-fit line.\n",
        "\n",
        "Solar radiation (X) generally increases with the demand for rental bikes (Y), as shown by the upward-sloping best-fit line.\n",
        "\n",
        "Both snowfall and rainfall (X) are associated with a decrease in the demand for rental bikes (Y), as indicated by the downward-sloping best-fit lines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq2qVbUGCUgG"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpKOlNVgCUgG"
      },
      "source": [
        "The gained insights for bussinees is the avg demand of rental bikes on the specific conditions of the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDzcmxA2CUgI"
      },
      "source": [
        "#### Chart - 15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8q9u2OsCUgJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Plot the correlation heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='inferno')\n",
        "\n",
        "# Set labels for better interpretation of the plot\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.ylabel('Feature/Property')\n",
        "plt.xlabel('Feature/Property')\n",
        "\n",
        "# Display the heatmap\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFQl1r2YCUgJ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_SE2AnYCUgJ"
      },
      "source": [
        "The corelation chart shows the relation between the two  specific feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN4XqXLbCUgJ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km4SFuqoCUgJ"
      },
      "source": [
        "A correlation coefficient close to +1 indicates a strong positive correlation, meaning that as one variable increases, the other also tends to increase.\n",
        "\n",
        "On the other hand, a correlation coefficient close to -1 indicates a strong negative correlation, suggesting that as one variable increases, the other tends to decrease.\n",
        "\n",
        "A correlation coefficient close to 0 indicates a weak or no correlation between the two variables. In this case, changes in one variable do not have a significant impact on the other variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "Research Hypothesis: The average bike count at any point in time is greater than 100.\n",
        "\n",
        "Null Hypothesis (H0): The average bike count is equal to 100.\n",
        "\n",
        "Alternative Hypothesis (Ha): The average bike count is greater than 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking a random sample of 500 data points for 'Rented Bike Count'\n",
        "names = df['Rented Bike Count'].sample(500)\n",
        "\n",
        "# Calculating the sample mean of 'Rented Bike Count'\n",
        "rented_bike_count_mean = np.mean(names)\n",
        "\n",
        "# Calculating the sample standard deviation of 'Rented Bike Count'\n",
        "rented_bike_count_std = np.std(names)\n"
      ],
      "metadata": {
        "id": "2fDXSb4_3dv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one = (rented_bike_count_mean-100)/(rented_bike_count_std/(np.sqrt(500)))"
      ],
      "metadata": {
        "id": "HIQ3ycS13nWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the probability\n",
        "probability_z = norm.cdf(one , 0, 1)\n",
        "print(probability_z)"
      ],
      "metadata": {
        "id": "18P8PoHV3v1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = 1-probability_z\n",
        "p1"
      ],
      "metadata": {
        "id": "HmkY8s3j33AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "We have chosen Z-test to obtain p-value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "\n",
        "\n",
        "As we are conducting a hypothesis test for the population mean, we have chosen to use the Z-test to calculate the p-value. The resulting probability is close to 100%, indicating that we have significant evidence to reject the null hypothesis (H0) that the average bike count in the city is equal to 100. Therefore, based on the sample data, we can confidently conclude that the average bike count at any point in time is greater than 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "\n",
        "\n",
        "The research hypothesis is that the average temperature at any point is greater than 10 degrees Celsius.\n",
        "\n",
        "Null Hypothesis (H0): The average temperature is equal to 10 degrees Celsius.\n",
        "\n",
        "Alternative Hypothesis (Ha): The average temperature is greater than 10 degrees Celsius."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Taking a random sample of 500 data points for 'Temperature'\n",
        "temp_data_sample = df['Temperature'].sample(500)\n",
        "\n",
        "# Calculating the sample mean of 'Temperature'\n",
        "temp_data_mean = np.mean(temp_data_sample)\n",
        "\n",
        "# Calculating the sample standard deviation of 'Temperature'\n",
        "temp_data_std = np.std(temp_data_sample)\n",
        "\n",
        "# Calculating the t-score for the one-sample t-test\n",
        "t_score_temp = (temp_data_mean - 10) / (temp_data_std / (np.sqrt(500)))\n",
        "\n",
        "# Displaying the calculated t-score\n",
        "t_score_temp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_z = norm.cdf(t_score_temp, 0, 1)\n",
        "print(prob_z)"
      ],
      "metadata": {
        "id": "Gik8ikfv5LP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = 1-prob_z\n",
        "p1"
      ],
      "metadata": {
        "id": "bflE4-z45O8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "We have chosen Z-test to obtain p-value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "As we conducted the hypothesis testing for the population mean, we utilized the Z-test to calculate the p-value. The resulting probability is 99%, indicating that we have substantial evidence to reject the null hypothesis (H0) which assumes the average temperature is equal to 10 degrees Celsius. Therefore, based on the sample data, we can confidently conclude that the average temperature at any point in time is greater than 10 degrees Celsius."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "\n",
        "\n",
        "The research hypothesis is that the standard deviation of humidity is equal to 20.\n",
        "\n",
        "Null Hypothesis (H0): The standard deviation of humidity is not equal to 20.\n",
        "\n",
        "Alternative Hypothesis (Ha): The standard deviation of humidity is equal to 20."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Taking a random sample of 50 data points for 'Humidity'\n",
        "humidity_sample = df['Humidity'].sample(50)\n",
        "\n",
        "# Calculating the sample variance of 'Humidity'\n",
        "sample_variance = (np.std(humidity_sample))**2\n",
        "\n",
        "# Calculating the test statistic for the chi-square test\n",
        "test_statistic = (49 * sample_variance) / (20*20)\n",
        "\n",
        "# Displaying the calculated test statistic\n",
        "test_statistic\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob = chi2.cdf(test_statistic,49)\n",
        "print(prob)"
      ],
      "metadata": {
        "id": "zsCAxhZ86N-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "\n",
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "We have chosen Chi2-test to obtain p-value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "As we conducted the hypothesis testing for the population standard deviation, we utilized the Chi-square test to calculate the p-value. The resulting probability is 45.53%, indicating that we do not have enough evidence to reject the null hypothesis (H0) which assumes that the standard deviation of humidity is not equal to 20. Therefore, based on the sample data, we do not have sufficient evidence to conclude that the standard deviation of humidity is 20."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values\n",
        "(No Missing Values Found)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Missing Values/Null Values Count\n",
        "missing_values = df.isna().sum()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "There were no missing values present in the database, no manipulations were done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After investigating and plotting box plots, we observed that the following variables have many outliers:\n",
        "\n",
        "Wind Speed\n",
        "\n",
        "Solar Radiation\n",
        "\n",
        "Rainfall\n",
        "\n",
        "Snowfall\n",
        "\n",
        "However, upon careful consideration, we concluded that these outlier values are not erroneous data points but rather represent meaningful and relevant insights. Therefore, there is no need to clip or remove these extreme values as they hold valuable information for our analysis.\n",
        "\n",
        "The code provided to handle the outliers can be uncommented if needed, but based on our findings, it is recommended to retain the outlier values for a more comprehensive and accurate understanding of the data."
      ],
      "metadata": {
        "id": "sx2mONYuJV-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# # Handling Outliers & Outlier treatments\n",
        "# numerical_vars = df.describe().columns\n",
        "# for var in numerical_vars:\n",
        "#   plt.figure(figsize=(2, 2))\n",
        "#   sns.boxplot(y=var, data=df)\n",
        "#   plt.xlabel(var)\n",
        "#   plt.ylabel('Values')\n",
        "#   plt.title(f'Box Plot for {var}')\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Outliers are observed in the following columns\n",
        "# outliers_col=['Wind Speed','Solar Radiation','Rainfall','Snowfall']\n",
        "\n",
        "# #writing a function to handle outliers in the dataframe\n",
        "# def cliping_outliers(df1):\n",
        "#     for col in df1[outliers_col]:\n",
        "#         # using IQR method to define range of upper and lower limit.\n",
        "#         q1 = df1[col].quantile(0.25)\n",
        "#         q3 = df1[col].quantile(0.75)\n",
        "#         iqr = q3 - q1\n",
        "#         lower_bound = q1 - 1.5 * iqr\n",
        "#         upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "#         # replacing the outliers with upper and lower bound\n",
        "#         df1[col] = df1[col].clip(lower_bound, upper_bound)\n",
        "#     return df1\n",
        "\n",
        "\n",
        "# # calling the function and handeling outliers\n",
        "# df = cliping_outliers(df)"
      ],
      "metadata": {
        "id": "SjRyNU5kfTzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # after handeling Outliers & Outlier treatments\n",
        "\n",
        "# for var in outliers_col:\n",
        "#   plt.figure(figsize=(2, 2))\n",
        "#   sns.boxplot(y=var, data=df)\n",
        "#   plt.xlabel(var)\n",
        "#   plt.ylabel('Values')\n",
        "#   plt.title(f'Box Plot for {var}')\n",
        "#   plt.show()"
      ],
      "metadata": {
        "id": "HooZpzI5hcQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "# convert object type data to dumy variables(binary form)\n",
        "\n",
        "df['Winter']=np.where(df[\"Seasons\"]=='Winter',1,0)\n",
        "df['Spring']=np.where(df[\"Seasons\"]=='Spring',1,0)\n",
        "df['Summer']=np.where(df[\"Seasons\"]=='Summer',1,0)\n",
        "df['Autumn']=np.where(df[\"Seasons\"]=='Autumn',1,0)\n",
        "\n",
        "df['Holiday']=np.where(df[\"Holiday\"]=='Holiday',1,0)\n",
        "df['Functioning Day']=np.where(df['Functioning Day']=='Yes',1,0)\n",
        "\n",
        "# Since Seasons is encoded into 4 new features we are dropping the orignal feature\n",
        "df.drop('Seasons',axis=1, inplace = True)\n",
        "\n",
        "x=['Month','Hour']\n",
        "for i in x:\n",
        "      df = pd.concat([df, pd.get_dummies(df[i], prefix=i, drop_first=True)], axis=1)\n",
        "      df = df.drop([i], axis=1)\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "In order to represent categorical variables as numerical values suitable for a machine learning model, we employed One-hot encoding. This process involved creating four new columns for the 'Seasons' column, each corresponding to a specific category ('Winter', 'Spring', 'Summer', and 'Autumn'). We assigned a value of 1 to the matching category and 0 to the other categories within each new column.\n",
        "\n",
        "For the 'Holiday' and 'Functioning Day' columns, which had two distinct values, we directly encoded them into binary form, using 0 and 1 to indicate the presence or absence of each category.\n",
        "\n",
        "Moreover, to handle the 'Month' and 'Hour' columns with 12 and 24 unique values, respectively, we applied One-hot encoding. This resulted in multiple new columns representing individual values within each category. To avoid multicollinearity, we dropped the first column from each set of encoded columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have created some features in the data wrangling section"
      ],
      "metadata": {
        "id": "pYIlssVEe0_a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# since day and week number are not correlated we are dropping them\n",
        "df = df.drop(['Day', 'Week Number'],axis=1)\n",
        "\n",
        "### removing multicollear\n",
        "df['Total Temp'] = 0.7*df['Temperature'] + 0.3*df['Dew Point Temperature']\n",
        "df=df.drop(['Temperature','Dew Point Temperature'],axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see there is multicollinearity between the columns 'Temperature' & 'Dew Point Temperature'. Hence we are creating a new column as 0.7 x Temperature + 0.3 x Dew point Temprature as Total Temperature"
      ],
      "metadata": {
        "id": "6UQLbne6CYpU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "In EDA, we extracted new features from the date column: date, month, and year.\n",
        "\n",
        "The 'Dew Point Temperature' feature was dropped due to collinearity with 'Temperature'.\n",
        "\n",
        "'Day' and 'Month' were also dropped as they showed low correlation with 'Rented Bike Count' (0.04 and 0.07, respectively)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "The remaining columns are equally important as they have average collineriaty between them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['Rented Bike Count'],kde=True)"
      ],
      "metadata": {
        "id": "0KyhXv4w2bmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after plotting hist plot we see that the rented bike count is Right skewed, so it is important to transform the data as seen in chart 13"
      ],
      "metadata": {
        "id": "tJidI3C9-nzb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "outputs": [],
      "source": [
        "# Transform Your data\n",
        "df['Rented Bike Count']=np.sqrt(df['Rented Bike Count'])\n",
        "sns.histplot(df['Rented Bike Count'],kde=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling\n",
        "we have used minmax scalar after spliting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have used minmax scalar after spliting the data"
      ],
      "metadata": {
        "id": "fIEBvVkTDkSM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction\n",
        "(we did not find it meaning full to further reduce dimentionality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "outputs": [],
      "source": [
        "# DImensionality Reduction (If needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5CmagL3EC8N"
      },
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKr75IDuEM7t"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x = df.drop(columns=['Rented Bike Count'], axis=1)\n",
        "y = np.sqrt(df['Rented Bike Count'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=.20,random_state=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(X_train)\n",
        "x_test = scaler.transform(X_test)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "CyM33UekjQ7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "As a standard practice we have split the data into 80-20 ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset\n",
        "(Not applicable in our case as the data is balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "outputs": [],
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initiating test and train dictionary for future reference and comparing values\n",
        "train_data={}\n",
        "test_data={}"
      ],
      "metadata": {
        "id": "ZldAjh28E2yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, X_test, y_train, y_test, output_name):\n",
        "    '''This function implements the given model and calculates the statistics.\n",
        "    It adds the results to the train and test dictionaries.\n",
        "    '''\n",
        "    # Fit the model\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_train, y_train)\n",
        "    print(f'The score for {output_name} is: {score}')\n",
        "\n",
        "    # Predict using the model\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    print('\\n')\n",
        "    print('-'*50)\n",
        "    print(f'Metrics for {output_name} train dataset')\n",
        "    print('-'*50)\n",
        "\n",
        "    # Calculate and print Mean Squared Error (MSE)\n",
        "    MSE_train = mean_squared_error(y_train, y_pred_train)\n",
        "    print(f'MSE : {MSE_train}')\n",
        "\n",
        "    # Calculate and print Mean Absolute Error (MAE)\n",
        "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "    print(f'Mean absolute Error : {mae_train}')\n",
        "\n",
        "    # Calculate and print Root Mean Square Error (RMSE)\n",
        "    RMSE_train = np.sqrt(MSE_train)\n",
        "    print(f'RMSE : {RMSE_train}')\n",
        "\n",
        "    # Calculate and print R-squared (R2)\n",
        "    r2_train = r2_score(y_train, y_pred_train)\n",
        "    print(f'R2 : {r2_train}')\n",
        "\n",
        "    # Calculate and print Adjusted R-squared (Adjusted R2)\n",
        "    # Formula => Adjusted R-squared = 1 - [(1 - R-squared) * (n - 1) / (n - p - 1)]\n",
        "    a_r2_train = 1 - (1 - r2_train) * ((X_train.shape[0] - 1) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
        "    print(f'Adjusted R^2: {a_r2_train}')\n",
        "\n",
        "    # Update the observed values to the train dictionary for future references\n",
        "    train_data[output_name] = MSE_train, mae_train, RMSE_train, r2_train, a_r2_train\n",
        "    print('\\n')\n",
        "\n",
        "    print('-'*50)\n",
        "    print(f'Metrics for {output_name} test dataset')\n",
        "    print('-'*50)\n",
        "\n",
        "    # Calculate and print Mean Squared Error (MSE)\n",
        "    MSE_test = mean_squared_error(y_test, y_pred_test)\n",
        "    print(f'MSE : {MSE_test}')\n",
        "\n",
        "    # Calculate and print Mean Absolute Error (MAE)\n",
        "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "    print(f'Mean absolute Error : {mae_test}')\n",
        "\n",
        "    # Calculate and print Root Mean Square Error (RMSE)\n",
        "    RMSE_test = np.sqrt(MSE_test)\n",
        "    print(f'RMSE : {RMSE_test}')\n",
        "\n",
        "    # Calculate and print R-squared (R2)\n",
        "    r2_test = r2_score(y_test, y_pred_test)\n",
        "    print(f'R2 : {r2_test}')\n",
        "\n",
        "    # Calculate and print Adjusted R-squared (Adjusted R2)\n",
        "    a_r2_test = 1 - (1 - r2_test) * ((X_test.shape[0] - 1) / (X_test.shape[0] - X_test.shape[1] - 1))\n",
        "    print(f'Adjusted R^2: {a_r2_test}')\n",
        "\n",
        "    # Update the observed values to the test dictionary for future references\n",
        "    test_data[output_name] = MSE_test, mae_test, RMSE_test, r2_test, a_r2_test\n",
        "    print('\\n')\n",
        "\n",
        "    # Plot the actual vs. predicted values\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.title(f'Actual vs. Predicted for {output_name}')\n",
        "    plt.plot(np.array(y_pred_test))\n",
        "    plt.plot(np.array(y_test))\n",
        "    plt.legend([\"Predicted\", \"Actual\"])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SdHvJQInwrnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1\n",
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "LiReg = LinearRegression()\n",
        "evaluate_model(LiReg, X_train, X_test, y_train, y_test, 'Linear Regression')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression is a statistical technique used to model the relationship between two variables, typically referred to as the independent variable (or predictor variable) and the dependent variable (or response variable). It assumes a linear relationship between these variables, where a change in the independent variable is associated with a constant change in the dependent variable.\n",
        "\n",
        "The goal of linear regression is to estimate the parameters of the linear equation that best fits the observed data. The equation is typically represented as:\n",
        "\n",
        "Y = mX + b"
      ],
      "metadata": {
        "id": "mcOHq0iE67Pt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "For Linear Regression we do not do Hyper parameter optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "Adjusted R^2 on Train set is 0.8186804773197106\n",
        "\n",
        "Adjusted R^2 on test set is 0.8207516355447193\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxgelGcAAFB4"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkfa-c98AFB5"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2\n",
        "# Lasso"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "evaluate_model(lasso, X_train, X_test, y_train, y_test, 'Lasso without Hyperparameter Tuning')"
      ],
      "metadata": {
        "id": "dGoGc4vzcqh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso,parameters, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_regressor.fit(X_train, y_train)\n",
        "print(f'The best fit alpha value is found out to be : {lasso_regressor.best_params_}')\n",
        "print(f'Using {lasso_regressor.best_params_} the negative mean squared error is: {lasso_regressor.best_score_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "lasso=Lasso(alpha=0.0001,max_iter=4000)\n",
        "evaluate_model(lasso, X_train, X_test, y_train, y_test, 'Lasso with Hyperparameter Tuning')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso, also known as L1 regularization, is a linear regression technique used in machine learning and statistics to prevent overfitting and select a subset of important features from a larger set of predictors. It adds a penalty term to the linear regression objective function, which is the absolute value of the coefficients multiplied by a tuning parameter called the regularization strength. This penalty encourages the model to shrink the coefficients of less important features to exactly zero, effectively eliminating them from the model. This results in a sparse model with a subset of predictors that are most relevant to the prediction task, making it useful for feature selection and model interpretability. Lasso is particularly effective when dealing with datasets that have a large number of predictors and may suffer from multicollinearity, as it can automatically perform feature selection and regularization simultaneously.\n",
        "\n"
      ],
      "metadata": {
        "id": "xQwDQL7S7Hap"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "We have used Grid search CV as hyperparameter optimization technique. It finds the optimal aplha value for which the model is able to perform better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "No significant improvement seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3\n",
        "#Ridge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge=Ridge()\n",
        "evaluate_model(ridge, X_train, X_test, y_train, y_test, 'Ridge without Hyperparameter Tuning')"
      ],
      "metadata": {
        "id": "H-7or4AwdKeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "ridge=Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,y_train)\n",
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "ridge= Ridge(alpha=1)\n",
        "# Fit the Algorithm\n",
        "evaluate_model(ridge, X_train, X_test, y_train, y_test, 'Ridge with Hyperparameter Tuning')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge is a type of regularization technique used in machine learning, particularly in linear regression. It helps prevent overfitting by adding a penalty term to the loss function during model training. The penalty term is proportional to the square of the magnitude of the model's coefficients, which are the parameters that determine the relationship between input features and the predicted output. Ridge regularization encourages the model to use smaller coefficients, resulting in a simpler and more generalizable model. It is also known as L2 regularization because it adds the squared L2 norm of the coefficients to the loss function. Ridge can be tuned with a hyperparameter called the regularization strength, which controls the trade-off between fitting the data and regularizing the model. A higher regularization strength results in more regularization and a simpler model, while a lower regularization strength allows the model to fit the data more closely. Ridge is widely used in machine learning for regression tasks when dealing with multicollinearity or high-dimensional data."
      ],
      "metadata": {
        "id": "b2kXtBaIE4y-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDQLFoF4Ahg3"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FVlLFuFAhg4"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS22ShxDAhg5"
      },
      "source": [
        "We have used Grid search CV as hyperparameter optimization technique. It finds the optimal aplha value for which the model is able to perform better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTvCwJClAhg6"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb7xShfyAhg7"
      },
      "source": [
        "No significant improvement seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO1pr-St_vwh"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6YlEJm9_vwh"
      },
      "source": [
        "We have used Grid search CV as hyperparameter optimization technique. It finds the optimal aplha value for which the model is able to perform better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3JaMDP0_vwi"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcofvD4V_vwm"
      },
      "source": [
        "No significant improvement seen, the model performance decreased comapred to linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGtXMbkuBWEX"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHOr8rO2BWEY"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model 4\n",
        "#ElasticNet"
      ],
      "metadata": {
        "id": "eNAR83MT08sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet = ElasticNet(alpha=0.001, l1_ratio=0.5)\n",
        "\n",
        "evaluate_model(elasticnet, X_train, X_test, y_train, y_test, 'ElasticNet')"
      ],
      "metadata": {
        "id": "MOJf3HDy1Er1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "ElasticNet is a statistical method used for linear regression, which combines the L1 (Lasso) and L2 (Ridge) regularization techniques. It aims to overcome the limitations of both methods by adding a mixture of both penalties to the linear regression model. ElasticNet introduces two hyperparameters, alpha and l1_ratio, which control the strength of regularization and the balance between L1 and L2 regularization, respectively. This allows ElasticNet to handle multicollinearity in the data, select relevant features, and achieve better prediction performance compared to Lasso or Ridge alone. In summary, ElasticNet is a flexible regularization technique that combines the advantages of Lasso and Ridge regularization to improve linear regression models by preventing overfitting and improving model interpretability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfx_yzkrAwTd"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNR0lwqMAwTf"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CzWXSaeAwTg"
      },
      "source": [
        "No Hyperparameter tuning for Elastic Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCyzOlEcAwTh"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bFUUg7FAwTi"
      },
      "source": [
        "No significant improvement seen, the model performance decreased comapred to linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWm8BVABiQa"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model 5\n",
        "# Random Forest"
      ],
      "metadata": {
        "id": "4BdgP573nNDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_model=RandomForestRegressor()\n",
        "evaluate_model(rf_model, X_train, X_test, y_train, y_test, 'Random Forest')\n"
      ],
      "metadata": {
        "id": "lbcDdRDsnVjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "uwZEbMR-9AHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest is a popular machine learning algorithm used for both classification and regression tasks. It is an ensemble method that combines multiple decision trees to make more accurate predictions. The algorithm creates a \"forest\" of decision trees by randomly selecting a subset of features and data samples from the training dataset. Each tree in the forest is trained independently on these subsets, and their predictions are combined to obtain the final output."
      ],
      "metadata": {
        "id": "sZDN4bLk9eeq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH0eatRXA1kk"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjvOpgCFA1km"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4tb-XyCA1km"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayii9I3VA1kn"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjXnpYNPA1ko"
      },
      "source": [
        "Improvement seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIVpaK1OBm8t"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXSRb8hoBm8u"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML model 6\n",
        "# Support Vector Regressor\n",
        "(just to check its performance on regression task)"
      ],
      "metadata": {
        "id": "ZZ0uCBl8s0DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "support_vector = SVR(kernel = 'rbf')\n",
        "evaluate_model(support_vector, X_train, X_test, y_train, y_test, 'Support Vector Regressor')"
      ],
      "metadata": {
        "id": "mkQFK9TMs8r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "CkLyOwDC9OX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Regressor (SVR) is a supervised machine learning algorithm used for regression tasks. It is based on the Support Vector Machine (SVM) algorithm, which is commonly used for classification tasks. SVR is designed to predict continuous numerical values rather than discrete classes."
      ],
      "metadata": {
        "id": "cT7u7J-F9W0b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJpWb9NrA8ep"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vv5ii0eA8er"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNakHHncA8es"
      },
      "source": [
        "No Hyperparameter tuning for Support vector Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UniAo5tA8es"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNhGrR_VA8et"
      },
      "source": [
        "it is found that this model fails drastically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KpyaOlPBrpQ"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUtoK_myBrpR"
      },
      "source": [
        "it is found that this model fails drastically"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML model 7\n",
        "# Decision Tree Regressor"
      ],
      "metadata": {
        "id": "SS4CgzHatyBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dtr = DecisionTreeRegressor()\n",
        "evaluate_model(dtr, X_train, X_test, y_train, y_test, 'Decision Tree Regressor')"
      ],
      "metadata": {
        "id": "p_-2stukt3_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "yvaqZUGP9Q8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Regressor is a machine learning algorithm used for regression tasks, which involves predicting a continuous target variable. It works by recursively splitting the feature space into subsets based on the values of input features, and then predicting the target value for each subset. The splits are determined based on a set of predefined rules or criteria, such as minimizing the variance of the target variable or maximizing the information gain. The resulting tree-like structure allows for easy interpretation and visualization. Decision Tree Regressor can handle both numerical and categorical features, and is capable of capturing non-linear relationships between features and the target variable. However, it is prone to overfitting and may not perform well on complex datasets with noisy or sparse data. Regularization techniques, such as pruning or setting maximum depth, can be applied to mitigate overfitting."
      ],
      "metadata": {
        "id": "tPLVhq6q9TYz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2B0k-FdA_0s"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkM_tcs1A_0u"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouXE-zvoA_0w"
      },
      "source": [
        "No Hyperparameter tuning for Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEUkOADNA_0x"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSOuS7xRA_0y"
      },
      "source": [
        "No significant improvement seen, the model performance decreased comapred to Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksZSdbeVBvlC"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7hXylBBvlD"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "-GWZeXEHu9jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = x.columns\n",
        "importances = rf_model.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "6yFMqqRRukjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting figure\n",
        "plt.figure(figsize=(8,10))\n",
        "plt.title('Importance of Feature')\n",
        "plt.barh(range(len(indices)), importances[indices], color='green', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices], fontsize = 8)\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Bsd8wnMXu3cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# # Save the File\n",
        "import pickle\n",
        "pickle_path = dir_path + 'RandomForestRegressor.pkl'\n",
        "\n",
        "# serialize process (wb=write byte)\n",
        "pickle.dump(rf_model, open(pickle_path,'wb'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the saved model from the pickle file\n",
        "Regression_model= pickle.load(open(pickle_path,'rb'))\n",
        "\n",
        "# Predicting the unseen data(test set)\n",
        "Regression_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the test and train stastics into a dataframe\n",
        "Test=pd.DataFrame(test_data,index=[\"Test MSE\", 'Test MAE', \"Test RMSE\",'Test R^2','Test Adjusted R^2'])\n",
        "Train=pd.DataFrame(train_data,index=[\"Train MSE\", 'Train MAE', \"Train RMSE\",'Train R^2','Train Adjusted R^2'])"
      ],
      "metadata": {
        "id": "HxKqDyWnMjgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.concat([Train, Test], axis=0)\n",
        "result_df.transpose()"
      ],
      "metadata": {
        "id": "jYs56jNMmxEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the data fro train\n",
        "Train.transpose()"
      ],
      "metadata": {
        "id": "ROK1Hz58MurR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the data fro test\n",
        "Test.transpose()"
      ],
      "metadata": {
        "id": "S64180zTMvlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "## Write the conclusion here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML model conclusion"
      ],
      "metadata": {
        "id": "ipLHWo9q_FDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Considering adjusted r^2 score on test stastics we have selected Random Forest as best performing model with accuracy of 91.4%***"
      ],
      "metadata": {
        "id": "F6u6krDt_NJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *** EDA Observations : ***\n",
        "\n",
        "95% of the days are working days (not holidays), and 4.9% are holidays.\n",
        "\n",
        "96.6% of the values are recorded as functioning days, while the remaining are non-functioning days.\n",
        "\n",
        "The data recorded for various seasons is almost equal (around 25% each).\n",
        "\n",
        "The data includes records for the years 2017 and 2018, with most of the data belonging to 2018 (91.5%) and the rest to 2017 (8.5%).\n",
        "\n",
        "It is observed that mostly the days are functional and not holidays.\n",
        "\n",
        "The data covers all seasons, providing a comprehensive analysis of functioning days and holidays.\n",
        "\n",
        "The captured data spans from January 12, 2017, to December 11, 2018.\n",
        "\n",
        "The total bikes rented on no holiday is 5,956,419 and on holidays is 215,895.\n",
        "\n",
        "The total bikes rented on functioning days is 6,172,314, and on non-functioning days, it is 0.\n",
        "\n",
        "The total bikes rented in 2018 is 5,986,984, and in 2017, it is 185,330.\n",
        "\n",
        "On a functioning day, the bike rented sum is zero, indicating no bikes were rented on non-functioning days, impacting the business negatively.\n",
        "\n",
        "During winters, the bikes are rented less, affecting the business negatively, while during summer, the impact is positive, and more bikes are rented.\n",
        "\n",
        "There is a significant spike in bike rentals starting from December 2017, indicating significant growth during that period.\n",
        "\n",
        "The demand for bikes is highest at 8 am and 6 pm, suggesting people are renting bikes for commuting to and from the office.\n",
        "\n",
        "Bike rentals during non-functioning days are zero.\n",
        "\n",
        "Bike demand is higher during summer and lower during winters.\n",
        "\n",
        "The analysis shows that bike rentals were more when the rainfall was 0.0.\n",
        "\n",
        "However, when excluding rainfall values of 0.0, it was observed that most rentals occurred during low rainfall values.\n",
        "\n",
        "People prefer to rent bikes when the wind speed is moderate, between 0.3 to 3.\n",
        "\n",
        "There is a minor impact of wind speed on bike renting preference.\n",
        "\n",
        "The demand for rental bikes is high when visibility is 2000, and low when solar radiation is 0.0.\n",
        "\n",
        "People do not prefer to rent bikes when solar radiation is above 0.05.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### *** Behaviour of People at Various Weather Conditions ***\n",
        "\n",
        "\n",
        "People tend to rent bikes when wind speed is between 0.3 to 4.\n",
        "\n",
        "High visibility (2000) leads to increased bike rentals.\n",
        "\n",
        "Dew point temperature between -0.25 to 25 results in higher bike rentals.\n",
        "\n",
        "Bike rentals are more when solar radiation is less (0.0).\n",
        "\n",
        "Lower rainfall (0.2) is associated with higher bike rentals.\n",
        "\n",
        "Bike rentals increase when snowfall is less (0.1).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### *** Various Weather Conditions : ***\n",
        "\n",
        "\n",
        "Temperature is normally distributed between -20 to 40.\n",
        "\n",
        "Humidity is normally distributed from 0 to 90.\n",
        "\n",
        "Wind speed is right-skewed, ranging from 0 to 7.\n",
        "\n",
        "Visibility is left-skewed, ranging from 0 to 2000.\n",
        "\n",
        "Dew point temperature ranges from -30 to 30.\n",
        "\n",
        "Solar radiation is highly right-skewed, with values from 0 to 3.5.\n",
        "\n",
        "Rainfall is highly right-skewed, ranging from 0 to 35.\n",
        "\n",
        "Snowfall is highly right-skewed, with values from 0 to 8.\n",
        "\n",
        "\n",
        "### *** Effect of Various Parameters on Renting Bikes : ***\n",
        "An increase in temperature (X) from -10 to 30 leads to an increase in demand for rental bikes (Y).\n",
        "\n",
        "For an increase in humidity (X), the demand for rental bikes decreases (Y).\n",
        "\n",
        "An increase in wind speed (X) from 0 to 3 leads to an increase in the demand for rental bikes (Y).\n",
        "\n",
        "There is no significant relationship between visibility (X) and the demand for rental bikes (Y).\n",
        "\n",
        "The demand for rental bikes increases with an increase in dew point temperature (X).\n",
        "\n",
        "The demand for rental bikes normally increases with an increase in solar radiation (X).\n",
        "\n",
        "The demand for rental bikes decreases with an increase in snowfall and rainfall (X)."
      ],
      "metadata": {
        "id": "N5_a8gpJ-YD0"
      }
    }
  ]
}